**스레드(Thread)** 가 실행의 단위임을 앎. 하지만 현대의 서버들은 수만 명의 사용자를 처리하기 위해 스레드를 수만 개 만들지 않음. 왜일까?

#### 스레드 모델의 한계: C10K 문제
- 메모리 비용: 스레드 하나당 독립적인 스택(Stack) 공간(보통 1MB 이상)이 필요함. 스레드 1만개면 메모리만 10GB를 소모함.
- 문맥 교환 오버헤드: CPU가 수만 개의 스레드를 번갈아 실행하느라 정작 실제 연산보다 **레지스터 저장/복원(Context Switch)** 에 더 많은 시간을 쓰게 됨.
- I/O 블로킹: 대부분의 스레드는 디스크를 읽거나 네트워크 응답을 기다리는 I/O 작업 동안 아무것도 못 하고 '대기(Blocked)' 상태로 자원을 점유함.

#### 비동기 I/O (Asynchronous I/O): 기다리지 않는 지혜
OS 레벨에서 지원하는 비동기 I/O는 "데이터가 준비될 때까지 나를 멈추지 마라"는 약속임.
- Blocking I/O (전통적): `read()` 호출 시 데이터가 올 때까지 쓰레드가 멈춤.
- Non-blocking / Async I/O: `read()`를 호출하면 즉시 리턴됨. 데이터가 준비되면 OS가 인터럽트나 이벤트 알림을 통해 알려줌.

#### 이벤트 루프 (Event Loop): 단일 스레드의 마법
이 지점에서 Node.js, Nginx, Redis 등이 사용하는 이벤트 루프 아키텍처가 등장함. 핵심은 **"일꾼(스레드)은 하나지만, 쉬지 않고 일한다"** 임.
1. 단일 스레드: 메인 루프는 하나만 존재함.
2. 비동기 요청: I/O 작업(DB 쿼리, 파일 읽기)이 발생하면 커널에 요청만 던지고 다음 작업을 처리하러감.
3. 이벤트 큐 (Event Queue): 커널에서 I/O 작업이 완료되면 결과가 큐에 쌓임.
4. 콜백 실행: 이벤트 루프는 한 바퀴 돌 때마다 큐를 확인하여 완료된 작업의 후속 조치(Callback)를 처리함.

연결고리: 이것은 마치 한 명의 요리사(CPU)가 여러 테이블의 주문(I/O)을 받아두고, 재료가 손질되는 동안 쉬지 않고 다른 요리를 만드는 것과 같음. 재료가 준비되었다는 종소리(Event)가 들리면 그때 다시 그 요리를 마무리함.

#### 커널의 조력자: epoll (Linux) / IOCP (Windows)
이벤트 루프가 수만 개의 연결을 효율적으로 감시할 수 있는 이유는 OS가 제공하는 고속 이벤트 통지 시스템 덕분임.
- 과거 (select/poll): 매번 모든 연결(File Descriptor)을 순회하며 "데이터 왔니?"라고 물어봐야 했음 ($O(N)$).
- 현재 (epoll/kqueue): 데이터가 도착한 연결들만 OS가 리스트로 묶어줌 ($O(1)$).
- 통찰: Allocator에서 단편화를 줄이기 위해 블록을 관리하듯, OS 커널은 수만 개의 소켓 연결을 효율적인 트리나 리스트 구조로 관리하여 사용자에게 알림을 줌.

# 핵심 요약
1. C10K 문제: 스레드가 너무 많아지면 메모리와 문맥 교환 비용 때문에 시스템이 붕괴됨.
2. Async I/O: CPU가 I/O 완료를 기다리며 노는 시간을 제거함.
3. 이벤트 루프: 단일 스레드와 비동기 메커니즘을 결합하여 오버해드 없이 수만 개의 동시 접속을 처리함.
4. epoll: OS 커널 수준의 최적화 도구를 사용하여 대규모 이벤트를 $O(1)$ 속도로 감지함.
