# ECS의 탄생 배경 - 하드웨어의 절규
CPU와 메모리 사이의 "속도 전쟁"을 이해해야 함.

## 폰 노이만 구조의 병목과 "메모리 장벽 (Memory Wall)"
컴퓨터 구조 수업에서 매우는 기본적인 구조는 CPU가 메모리(RAM)에서 데이터를 가져와 연산하는 방식
- 과거: CPU 속도와 메모리 속도가 비슷했음. CPU가 "데이터 줘!"하면 메모리가 바로 줬음.
- 현재: CPU의 연산 속도는 비약적으로 발전했지만, 메모리의 접근 속도는 그만큼 빨라지지 못했음.

이로 인해 **메모리 장벽(Memory Wall)** 현상이 발생함. CPU는 데이터를 기다리느라(Stall) 수백 사이클을 낭비하게 됨. 현대의 고성능 프로그래밍은 **"CPU가 노는 시간을 어떻게 줄일 것인가?"** 가 핵심.

## 캐시(Cache)와 캐시 라인(Cache Line)
1. CPU가 데이터 A를 요청함.
2. 캐시에 없으면 (Cache Miss), RAM에서 A를 포함한 64바이트 블록을 읽어와 캐시에 채음.
3. 만약 다음에 필요한 데이터 B가 A 바로 옆에 있었다면, B는 이미 캐시에 있으므로(Cache Hit) 즉시 처리 가능.

## OOP(객체 지향 프로그래밍)의 배신
전통적인 OOP 방식(Game Object 패턴)이 왜 하드웨어 입장에서 비효율적인지 보겠음.

#### 포인터 체이싱 (Pointer Chasing)
OOP에서는 객체들이 힙(Heap) 메모리 여기저기에 산재해 있고, 서로를 포인터로 가리킴.
- `player -> weapon -> Stat` 처럼 포인터를 따라가며 참조.
- 하드웨어 입장: "주소 0x1000 갔다가, 갑자기 0x9000 갔다가, 다시 0x2000 가라고?"
- 이는 연속적인 메모리 접근을 불가능하게 만들어 매번 캐시 미스를 유발함.

### 데이터 파편화와 AoS (Array of Structures)
OOP는 보통 AoS 구조를 가짐.
```c++
// (개념적 예시)
struct GameObject {
	bool isDead; // 1 byte
	Vector3 position; // 12 bytes
	Matrix4 transform; //64 bytes
	AIClass* ai; // 8 bytes
	// ... 기타 수많은 데이터
};
```

만약 1000개의 유닛의 `position`만 업데이트하고 싶다고 가정.
1. CPU는 1번 객체를 로드함 (64바이트 캐시 라인).
2. `position`을 갱신함
3. 하지만 캐시 라인에는 지금 당장 필요 없는 `transfrom`, `ai`, `isDead` 같은 **쓰레기 데이터 (Cold Data)** 가 같이 딸려 왔음.
4. 유요한 데이터(`position`)는 캐시 라인 64바이트 중 극히 일부.
5. 결국 대역폭(Bandwidth) 낭비와 캐시 효율 저하로 이어짐.

## ECS의 설계 철학: 데이터 중심 (Data-Oriented)
ECS는 여기서 발상의 전환을 함.
	**"객체(Entity)는 중요하지 않다. 데이터(Component)의 묶음이 중요하다."**
하드웨어 친화적으로 가기 위해 데이터 구조를 SoA (Structure of Arrays) 형태로 뒤집음.
- AoS (OOP): `[위치, 체력, 이름], [위치, 체력, 이름], ...`
- SoA (ECS): `[위치, 위치, ...], [체력, 체력, ...], [이름, 이름, ...]`
이렇게 하면, "모든 유닛의 위치를 업데이트해라"라는 명령이 떨어졌을 때:
1. CPU는 `Position` 배열만 쫙 읽어옴.
2. 캐시 라인(64바이트) 하나에 `Position` 데이터가 꽉꽉 채워져 들어옴. (Vector3가 12바이트라면 약 5개의 위치 데이터가 한 번에 로드됨)
3. 버리는 데이터 없이 캐시 적중률(Cache Hit Rate)이 극대화 됨.

# 요약
1. 하드웨어 제약: CPU는 빠르지만 메모리는 느리다. 캐시 미스는 성능의 주적.
2. OOP의 문제: 데이터가 흩어져 있고(포인터), 불필요한 데이터가 함께 로드되어 캐시 효율이 떨어짐.
3. ECS의 접근: 데이터를 종류별로 연속된 메모리에 모아서(SoA), 캐시 적중률을 높이고 CPU 파이프라인 효율을 극대화함.
