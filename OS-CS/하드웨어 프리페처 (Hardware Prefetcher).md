CPU와 메모리 사이의 거대한 속도 차이(Memory wall)를 극복하기 위해존재하는 **"에지 능력자"**

# 왜 필요한가? (The Motivation)
CPU는 초당 수십억 번(`GHz`) 연산하지만, 메인 메모리(RAM)는 상대적으로 매우 느림.
- CPU: "데이터 내놔!" (1사이클 소요)
- RAM: "잠시만요..." (데이터 찾는 데 100~300사이클 소요)
이 기다리는 시간(Latency) 동안 CPU는 아무것도 못 하고 놈(Stall). 하드웨어 프리페처는 이 시간을 없애기 위해 **"CPU가 다음에 필요로 할 것 같은 데이터를 미리 짐작해서 캐시(Cache)로 가져다 놓는 장치"**
	 비유: 요리사(CPU)가 양파를 썰고 있음. 보조 요리사(Prefetcher)는 요리사가 "양파 더 줘."라고 말하기 전에, 눈치껏 냉장고 (RAM)에서 다음 양파를 꺼내 도마 옆(Cache)에 미리 둠.

# 동작 원리: 패턴 인식 (Pattern recognition)
프리페처는 마법을 부리는 게 아니라, 메모리 접근 패턴을 감시함. 크게 두 가지 방식이 있음.
### 순차적 프리페칭 (Sequential / Next-line Prefetching)
가장 단순하고 흔한 방식
- 동작: CPU가 메모리 주소 `0x1000`에 있는 데이터를 읽고, 곧이어 `0x1004`를 읽음.
- 판단: "아, 이 주인님이 데이터를 순서대로 읽는구나!"
- 실행: CPU가 시키지도 않았는데 `0x1008`, `0x100C`...를 미리 RAM에서 가져와 캐시에 넣음.
- C언어 적용: **배열(Array)** 을 `for` 문으로 순회할 때 엄청난 성능 향상을 가져옴.

### 스트라이드 프리페칭 (Stride Prefetching)
조금 더 똑똑한 방식. '보폭(Stride)'을 분석.
- 동작: CPU가 `0x1000`, 그다음 `0x1010`, 그다음 `0x1020`을 읽음. (16바이트씩 점프)
- 판단: "주인님이 16바이트 간격으로 건너뛰며 읽네?"
- 실행: 다음에 읽을 것으로 예상되는 `0x1030`을 미리 가져옴.
- C언어 적용: 구조체 배열에서 특정 멤버 변수만 읽을 때, 또는 **다차원 배열의 열(Column)** 을 따라 읽을 때 발동.

# 프리페처 친화적인 코드 작성법 (Data Oriented Design)
임베디드 C/C++ 프로그래머가 꼭 알아야 할 **"하드웨어 프리페처를 춤추게 하는 코딩 스타일"**
### 연결 리스트 (Linked List) vs 배열(Array)
- 배열: 메모리가 연속적이므로 프레피처가 100% 예측 성공함. 캐시 적중률(Hit Rate)이 최상.
- 연결 리스트: `Node->next`는 메모리상에서 어디로 튈지 모르는 랜덤 주소. 프리페처는 패턴을 찾을 수 없어 작동을 멈춤.
	- 결과: 매 노드 이동마다 RAM 접근 지연(Latency)을 온몸으로 맞아야 함.

### 행 우선(Row-major) vs 열 우선(Column-major) 순회
C언어의 2차원 배열은 메모리에 행(Row) 순서대로 저장.

# 프리페처의 부작용: 캐시 오염 (Cache Pollution)
프리페처가 항상 옳은 것은 아님.
- 상황: CPU는 `0x1000`, `0x1004`를 읽고 루프를 끝냈는데, 프리페처가 신나서 `0x1008`부터 `0x1040`까지 캐시에 다 채움.
- 문제: 
	1. 캐시 오염: 정작 필요한 다른 데이터가 캐시에서 밀려났음.
	2. 대역폭 낭비: 쓰지도 않은 데이터를 가져오느라 시스템 버스(Bus)가 바쁨.
- 대응: 매우 제한된 자원을 가진 임베디드 시스템이나, 랜덤 엑세스가 극단적으로 많은 데이터베이스 서버 등에서는 **일부러 프리페처를 끄기도 함.** (보통 BIOS나 특수 레지스터 설정으로 가능)

# 소프트웨어 프리페칭(`__builtin_prefetch`)
하드웨어가 패턴을 못 찾는 복잡한 알고리즘(예: 이진 탐색, 해시 테이블)을 짠다면? 프로그래머가 직접 **"야, 이거 곧 쓸 거니까 가져와"** 라고 명령할 수 있음.

GCC/Clang 컴파일러 내장 함수:
```c
// __builtin_prefetch(const void *addr, int rw, int locality)
// addr: 가져올 주소
// rw: 0(읽기), 1(쓰기)
// locality: 0(한번 쓰고 버림) ~ 3(계속 쓸 거임)

for (int i = 0; i < N; i++) {
	// 1. 현재 데이터 처리
	process(data[i]);
	
	// 2. 미래 데이터(약 3~4칸 뒤)를 미리 가져오라고 명령
	// 이렇게 하면 data[i+4]를 처리할 때쭘엔 이미 데이터가 캐시에 도착해 있음.
	__builtin_prefetch(&data[i+4], 0, 3);
}
```

	주의: 소프트웨어 프리페칭은 앙냘의 검임. 타이밍을 잘못 맞추면 오히려 오버헤드(명령어 처리 시간)만 늘어남. 반드시 프로파일링(성능 측정)을 하면서 적용해야 함.

# 요약
1. 하드웨어 프리페처는 메모리 접근 패턴을 읽어서 미리 데이터를 캐시에 가져오는 CPU의 도우미임.
2. **순차 접근(배열)** 과 **일정한 간격(Stride)** 을 가장 좋아함.
3. **랜덤 접근(포인터 체이닝)** 은 프리페처를 무력화시킴.
4. 임베디드 고수라면 "데이터가 메모리에 어떻게 깔려 있는지" 상상하며, 프리페처가 예측하기 쉬운 코드(Data Locality)를 작성해야 함.

하드웨어와 소프트웨어의 경계에 있는 아주 재미있는 주제.