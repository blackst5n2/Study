**캐시 최적화 기법** 과 **고급 병렬 처리**.

# 캐시 최적화 심화: 교체 정책 (Replacement Policy)
캐시가 가득 찼을 때, 새 데이터를 넣기 위해 **어떤 기존 데이터(라인)** 을 쫓아낼지 결정하는 규칙을 **교체 정책(Replacment Policy)** 이라고 함. 이 정책이 캐시 미스율을 결정함.

#### LRU (Least Recently Used)
- 원리: 가장 오랫동안 사용되지 않은(Least Recently Used) 데이터를 쫓아냄.
- 장점: 이론적으로 미스율을 가장 낮출 수 있는 최적의 정책.
- 단점: **하드웨어 구현이 매우 복잡함.** 모든 캐시 라인의 사용 순서를 추적해야 하므로, 캐시 크기가 커지면 회로가 복잡해짐.

#### FIFO (First In, First Out)
- 원리: 캐시에 **가장 먼저 들어온** 데이터를 가장 먼저 쫓아냄.
- 장점: 구현이 매우 간단함. (단순한 큐(Queue) 구조)
- 단점: 최근에 자주 사용되는 데이터일지라도, 오래되었다는 이유만으로 쫓겨날 수 있어 성능이 나쁨.

#### Random
- 원리: 무작위로 데이터를 선택하여 쫓아냄.
- 장점: 매우 간단하고 빠름.
- 특징: 의외로 복잡한 **LRU와 유사한 성능** 을 보일 때도 있어, 비용 대비 효율성 때문에 채택되는 경우도 있음.

	현실의 CPU: 실제 CPU는 완벽한 LRU 대신, **PLRU (pseudo LRU)** 나 다른 효율적인 근사 알고리즘을 사용함. 완벽한 LRU의 복잡성을 피하면서도 성능을 최대한 높이려는 절충안.

# 명령어 수준 병렬성 (ILP: Instruction-Level Parallelism)
파이프라인이 여러 명령어를 겹처서 실행하는 것이라면, ILP는 **클럭당 더 많은 명령어를 동시에** 실행하는 고급 기법.

#### 슈퍼스칼라 (Superscalar)
- 원리: CPU 내부에 **여러 개의 실행 유닛(Execution Unit)** 을 만들어, **여러 명령어를 한 클럭에 동시에** 실행하는 기법.
	- 예시: 덧셈 유닛, 곱셈 유닛, 메모리 유닛이 모두 있다면, 한 클럭에 덧셈, 곱셈, 메모리 로드 명령을 동시에 실행할 수 있음.
- 요구사항: 컴파일러나 CPU 내부 로직이 명령어들 사이에 **데이터 의존성(Data Dependency)** 이 없는지 정확히 분석해야 함.

#### 비순차적 실행 (Out-of-Order Execution)
- 원리: 코드가 순서대로(In-Order) 들어오더라도, **데이터 의존성이 없는 명령어** 는 **순서르 ㄹ무시하고** 먼저 실행하는 기법.
- 예시:
```
1. A = B + C // (B, C 로드 기다리는 중)
2. X = Y * Z // (A와 무관하므로 먼저 실행)
3. D = A + X
```
CPU는 1번 명령이 B와 C를 기다리는 동안, 2번 명령을 먼저 실행하여 유휴 시간을 줄임.

- 임베디드 연결: 단순한 임베디드 코어(예: Cortex-M)는 이 복잡한 로직을 구현하지 않고 **순차적 실행(In-Order)** 을 고수함. 고성능 애플리케이션 코어(예: Cortex-A)나 PC의 CPU에서만 사용됨.

# ISA의 진화: SIMD (Single Instruction, Multiple Data)
하나의 명령어로 여러 데이터를 동시에 처리하는 병렬 처리 방식.
- 원리: CPU 내부에 **벡터 레지스터** 라는 특수 레지스터를 추가하여, 하나의 명령(`VADD`)만으로 4개 혹은 8개의 숫자 쌍을 동시에 덧셈함.
- 활용:
	- 멀티미디어 처리: 이미지의 모든 픽셀 값을 일괄적으로 처리하거나, 오디오 필터링에 사용됨.
	- 머신러닝: 행렬 연산(ML의 핵심)을 초고속으로 처리하는 데 사용됨.
- 예시: Intel의 SSE/AVX, ARM의 NEON 확장 기능. (임베디드 환경에서도 성능이 중요한 DSP/ML 작업에 필수적으로 활성화하여 사용됨.)

