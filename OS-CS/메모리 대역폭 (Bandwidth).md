**메모리 대역폭(Memory Bandwidth)** 은 이전에 배운 '버스(Bus)'와 `프리페처` 개념이 합쳐져서 만들어내는 **"데이터 이동의 총량(Throughput)"**

CPU가 아무리 빠르고(클럭이 높고), 프리페처가 예측을 잘해도, 데이터가 지나다니는 `도로의 폭`이 좁으면 전체 시스템 성능은 떨어짐. 임베디드 프로그래머에게 대역폭은 시스템의 한계 성능을 결정하는 중요한 물리적 제약.

# 대역폭의 정의: "고속도로의 차선 수"
- 지연 시간(Latency): 데이터 하나를 요청했을 때 도착하기까지 걸리는 시간 (빠를수록 좋음, 단위: ns).
- 대역폭(Bandwidth): 1초 동안 이동시킬 수 있는 데이터의 양 (클수록 좋음, 단위: GB/s)/
	- 비유:
		- 지연 시간: 서울에서 부산까지 페라리(CPU)가 한 번 가는 데 걸리는 시간.
		- 대역폭: 고속도로가 2차선이나 16차선이냐의 차이. 한 번에 얼마나 많은 화물(데이터)을 나를 수 있는가?

임베디드 시스템, 특히 영상 처리를 하거나 디스플레이를 켜는 시스템에서는 지연 시간보다 대역폭이 더 중요할 때가 많음.

# 대역폭 계산 공식
하드웨어 스펙을 보고 이론적인 최대 속도를 계산할 줄 알아야 함.
$$대역폭(Bandwidth) = 버스 폭(Width) \times 클럭 주파수(Frequency) \times 채널 수$$
- 버스 폭 (Bus Width): 한 번에 전송 가능한 비트 수 (16bit, 32bit, 64bit 등)
- 클럭 (Clock): 1초에 전송하는 횟수 (Hz)
- 데이터 레이트 (Data Rate): DDR(Double Data Rate) 메모리의 경우 클럭당 2번 전송하므로 2를 곱합니다.
예시 (일반적인 임베디드 MCU):
- 시스템 버스 폭: 32bit (4 Byte)
- 버스 클럭: 100MHz
- 대역폭 4 Byte x 100,000,000 Hz = 400 MB/s

즉, 이 시스템은 1초에 최대 400MB의 데이터만 옮길 수 있음. 이 이상을 요구하면 CPU는 데이터를 기다리며 멈춤(Stall)

# 임베디드 개발자가 겪는 대역폭 문제: "버스 경쟁(Bus Contention)"
PC는 CPU용 메모리와 그래픽카드(GPU)용 메모리가 따로 있어서 도로가 분리되어 있음. 하지만 임베디드(SoC)는 하나의 시스템 버스와 하나의 메모(RAM)를 여러 장치가 공유함. 여기서 문제가 발생함.

시나리오:
1. LCD 컨트롤러: 화면을 표시하기 위해 RAM에서 초당 60번씩 엄청난 양의 픽셀 데이터를 가져감(대역폭의 50% 점유)
2. DMA (Direct Memory Access): 센서 데이터를 RAM으로 복사하고 있음. (대역폭의 30% 점유)
3. CPU: 이제 코드를 실행하려고 RAM에 저급하려는데, 남은 대역폭이 20%밖에 없음.

결과: CPU 성능이 아무리 좋아도, 버스가 꽉 차서(Traffic Jam) 코드가 느리게 실행됨. 이를 **메모리 대역폭 병목(Memory Bandwidth Bottleneck)** 이라고 함.

# 대역폭을 절약하는 C/C++ 프로그래밍 기법
하드웨어의 물리적 대역폭을 늘릴 수는 없으므로, 프로그래머가 효율적으로 써야 함.

### 정렬된 접근 (Aligned Access)
32비트 버스 시스템에서 데이터는 4바이트 단위로 이동함.
- Aligned (좋음): 4의 배수 주소(`0x1000`)에 있는 `int`를 읽으면, 한 번의 버스 트랜잭션으로 끝남.
- Misaligend (나쁨): `0x1001` 번지에 있는 `int`를 읽으려면?
1. `0x1000` ~ `0x1003`을 읽음.
2. `0x1004` ~ `0x1007`을 읽음.
3. CPU 내부에서 잘라 붙임.
	- 결과: 대역폭을 2배로 낭비하고 속도도 느려짐. (일브 CPU는 아예 에러를 냄)
	Tip: 구조체(`struct`)를 짤 때 **패딩(Padding)** 이 들어가는 이유가 바로 이 대역폭 효율(Alignment)을 맞추기 위해서임.
### 버스트 모드 (Burst Mode) 활용
메모리는 "한 번지(`0x10`)"를 읽는 것보다 "연속된 번지 4개(`0x10, 0x11, 0x12 0x13`)"를 읽는 것이 훨씬 빠름. (수도꼭지를 틀었다 잠갔다 하는 것보다, 한 번 틀어서 물통을 채우는 게 빠른 것과 같음)
- `memcpy` 같은 표준 라이브러리 함수는 하드웨어의 버스트 전송(Burst Transfer) 기능을 사용하여 대역폭을 극한까지 뽑아냄. `for` 문으로 1바이트씩 복사하는 것보다 `memcpy`가 훨씬 빠른 이유임.

### TCM (Tightly Coupled Memory) 사용
많은 임베디드 MCU(예: ARM Cortex-M)에는 TCM이라는 특별한 메모리 영역이 있음.
- 특징: 시스템 버스를 거치지 않고 CPU와 전용 고속도로로 직접 연결된 작은 RAM임.
- 전략: 인터럽트 벡터 테이블이나, 정말 자주 실행되는 핵심 알고리즘 코드, 스택(Stack)을  TCM 영역에 배치하면 버스 경쟁 없이 항상 최고 속도를 보장받을 수 있음.

# 요약
1. **대역폭(Bandwidth)** 은 데이터가 이동하는 도로의 폭이며, 시스템의 처리 한계를 결정.
2. 공유 자원의 비극: 임베디드에서는 CPU, DMA, 디스플레이가 하나의 버스 대역폭을 나눠 쓰기 때문에 서로 간섭(Bus Contention)이 일어남.
3. 프로그래머의 역할:
	- 데이터 **정렬(Alignment)** 지켜서 버스 낭비를 막는다.
	- 대량의 데이터 복사는 `for`문 대신 최적화된 **`memcpy`** 나 DMA를 사용한다.
	- 중요한 코드/데이터는 버스 경쟁이 없는 TCM이나 내부 SRAM에 배치한다.

이 개념은 나중에 임베디드 시스템의 성능이 안 나올 때, "CPU는 노는데 왜 느리지?"라는 의문을 해결하는 핵심 열쇠가 됩니다. (대부분 범인은 메모리 대역폭이기 때문.
