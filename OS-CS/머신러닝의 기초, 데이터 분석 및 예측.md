머신러닝(Machine Learning)은 복잡한 규치긍ㄹ 프로그래머가 직접 코딩하는 대신, 데이터를 통해 스스로 학습하여 규칙을 찾아내는 컴퓨터 과학의 한 분야. 임베디드에서는 센서 데이터를 기반으로 **예측(Prediction)** 이나 **분류(Classification)** 를 수행할 때 필수적임.

# 학습의 세 가지 유형
머신러닝 알고리즘은 크게 세 가지 방식으로 데이터를 학습함.

| 유형                             | 설명                                                   | 임베디드 예시                                        |
| ------------------------------ | ---------------------------------------------------- | ---------------------------------------------- |
| 지도 학습 (Supervised Learning)    | 정답(Label)이 있는 데이터를 이용해 학습함. "이 데이터는 고양이, 저 데이터는 강아지" | 온도/습도 센서 데이터와 함께 '정상' 또는 '이상'이라는 레이블을 주고 학습.   |
| 비지도 학습 (Unsupervised Learning) | 정답이 없는 데이터에서 숨겨진 패턴이나 그룹(Cluster)을 스스로 발견함.          | 공장 기계 진동 데이터를 분석하여, 기존과 다른 새로운 이상 패턴을 자동으로 분류. |
| 강화 학습 (Reinforcement Learning) | 보상(Reward)을 최대화하는 방향으로 시행착오를 통해 학습함.                 | 로봇 팔이나 드론의 제어 알고리즘 학습.                         |

# 신경망 (Neural Network)의 기본 구조
인공 신경망은 사람의 뇌 구조를 모방한 계산 모델이며, 머신러닝의 핵심 도구.
- 뉴런 (Neuron / Node): 정보를 받아 처리하고 전달하는 기본 단위. 각 뉴런은 입력값에 **가중치(Weight)** 를 곱하고 **편향(Bias)** 을 더한 후, **활성화 함수(Activation Function)** 를 통과시켜 다음 뉴런으로 전달함.
- 가중치 (Weight): 데이터의 중요도를 나타내는 값. 학습 과정은 결국 이 가중치를 최적화하는 과정..
- 활성화 점수 (Activation Function): 뉴런의 출력을 비선형적으로 변형시키는 함수. (예: ReLU, Sigmoid). 이 함수 덕분에 신경망이 복잡한 패턴을 인식할 수 있음.
- 레이어 (Layer): 뉴런들이 모여 층을 이룸.
	- 입력 레이어 (Input Layer): 센서 데이터나 이미지 픽셀 값이 들어오는 곳.
	- 은닉 레이어 (Hidden Layer): 복잡한 계산이 일어나는 중간 단계.
	- 출력 레이어 (Output Layer): 최종 결과(예: 온도 예측값, 이미지 분류)가 나오는 곳.

# 학습의 원리: 역전파 (Backpropagation)
신경망이 어떻게 똑똑해지는지, 즉 가중치를 어떻게 업데이트하는지에 대한 알고리즘.
1. 순전파 (Forward Propagation): 입력 데이터를 신경망에 통과시켜 예측값을 출력함.
2. 손실 계산 (Loss Calculation): 예측값과 실제 정답(Label) 사이의 오차(Loss)를 계산함. (오차가 클수록 나쁜 모델)
3. 역전파 (Backward Propagation): 이 오차를 출력 레이어에서 입력 레이어 방향으로 거꾸로 전파함.
4. 가중치 업데이트: 전파된 오차 정보를 이용하여 각 가중치를 얼마나, 어느 방향으로 수정해야 오차가 줄어들지 계산하고 업데이트함. (주로 경사 하강법 사용)

	임베디드 연결: 임베디드 시스템에서는 이 학습 과정(Backpropagation)을 수행하기 어려움. 대신, PC에서 학습을 완료한 최종 가중치 값과 신경만 구조만 가져와서 **추론(Inference)** 만 수행함. 이것이 **엣지 AI (Edge AI)** 의 기본.

# LLM (대규모 언어 모델)과의 연결
LLM은 방대한 텍스트 데이터로 학습된 매우 거대한 신경망.
- 원리: 기본적으로 다음에 올 단어(토큰)을 예측하는 훈련을 함. 이 예측 능력이 쌓여 문장을 만들고, 문맥을 이해하고, 추론까지 가능하게 만듦.
- 임베디드 연결: 일반적인 LLM은 메모리가 수백 GB가 필요하므로 임베디드에서 직접 구동할 수 없음. 대신, **경량화된 작은 언어 모델(Small Language Model, SLM)** 을 임베디드 장치에 올려 단순한 자연어 처리나 로컬 명령어 해석에 사용하려는 연구가 활발.

