LSH는 전통적인 해시 테이블이 '완벽한 일치'를 찾는 데 중점을 둔 것과 달리, **'유사한 데이터'** 를 효율적으로 찾는 것을 목표로 함. 이는 검색 엔진, 추천 시스템, 이미지 검색 등 현대 AI 서비스의 기반이 됨.

# LSH (Locality-Sensitive Hashing)
#### LSH의 필요성 (고차원 벡터의 저주)
- 문제: AI와 머신러닝에서 데이터(이미지, 텍스트, 사용자 선호도)는 수백, 수천 차원의 벡터로 표현됨. 두 벡터의 유사도(Similarity)를 측정하려면 모든 차원을 비교해야 함.
- 비효율성: 데이터가 수백만 개일 경우, 새로운 벡터 하나가 들어올 때마다 모든 기존 벡터와 비교해야하므로 ($O(N)$), 고차원 공간에서는 유사한 이웃을 찾는 속도가 급격히 느려짐. (이를 **차원의 저주(Curse of Dimensionality)** 라고 함.)
- LSH의 목표: 고차원 벡터의 유사도 탐색 시간을 $O(N)$에서 $O(1)$에 가깝게 줄이는 것임.

#### LSH의 핵심 원리: '유사한 것은 같은 곳에 해시하라'
LSH는 이름 그대로 **지역성(유사성)** 에 민감하게 반응하는 해시 함수를 사용함.

##### 핵심 원리:
1. LSH 함수: 일반 해시 함수와 달리, LSH 함수는 유사한 입력 벡터($V_1 \approx V_2$)가 같은 해시 값($H(V_1) = H(V_2)$)을 가질 확률이 높도록 설계됨.
2. 버킷 매핑: 이 해시 값을 기반으로 벡터를 해시 테이블의 버킷에 저장함.
3. 탐색 가속: 새로운 쿼리 벡터가 들어오면, 해시 함수를 통해 계산된 버킷만 확인함. 이 버킷에는 쿼리 벡터와 유사한(같은 해시 값을 가진) 벡터들만 모여 있을 확률이 높으므로, 전체 데이터를 탐색할 필요가 없어짐.

#### 대표적인 LSH 기술 (예시)
LSH를 구현하는 구체적인 기술은 사용되는 유사도 척도에 따라 다름.

| LSH 기법            | 사용되는 유사도 척도                 | 주로 사용되는 데이터                    |
| ----------------- | --------------------------- | ------------------------------ |
| SimHash           | 해밍 거리(Hamming Distance)     | 텍스트 문서의 유사도 비교, 중복 문서 제거       |
| MinHash           | 자카드 유사도(Jaccard Similarity) | 대규모 집합 간의 유사성 (예: 웹페이지 집합 유사도) |
| Random Projection | 코사인 유사도(Cosine Similarity)  | 이미지, 음성, 딥러닝 임베딩 펙터            |

#### LSH의 특징: 확률적 탐색
LSH는 해시 충돌(Collision)을 단점으로 보는 일반 해시와 달리, 유사한 데이터끼리의 의도적인 충돌을 장점으로 활용함.
- 성능 vs. 정확도: LSH는 $O(1)$에 가까운 속도를 얻는 대신, 가장 정확한 유사 벡터를 놓칠 수 있는 **확률적 오류(False Negative)** 를 감수함.
- 실제 적용: 검색 엔진이 "가장 비슷한 이미지 100개"를 찾아야 할 때, 정확히 100개를 찾는 것보다 매우 높은 확률로 95개 이상을 빠르게 찾는 것이 중요할 때 사용됨.
